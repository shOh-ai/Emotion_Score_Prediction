{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba74c7cc",
   "metadata": {},
   "source": [
    "## EEG data grouing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5220efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 경로 설정\n",
    "eeg_folder_path = '/Users/sh_oh/Library/CloudStorage/Dropbox/Data/2023-1/BDP/ECSMP_Dataset/EEG_train_csv'\n",
    "\n",
    "# 파일 목록 가져오기\n",
    "file_list = os.listdir(eeg_folder_path)\n",
    "\n",
    "# 그룹별로 파일들을 그룹화\n",
    "grouped_files = {}\n",
    "for file_name in file_list:\n",
    "    group_key = file_name[:11]\n",
    "    if group_key == \".DS_Store\":  # .DS_Store 그룹은 건너뜁니다\n",
    "        continue\n",
    "    if group_key not in grouped_files:\n",
    "        grouped_files[group_key] = []\n",
    "    grouped_files[group_key].append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f088999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터를 저장할 리스트\n",
    "new_data = []\n",
    "\n",
    "# 그룹별로 데이터 처리\n",
    "for key, file_names in grouped_files.items():\n",
    "    # 그룹 내 파일들을 읽어와 데이터 리스트에 추가\n",
    "    group_data = []\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(eeg_folder_path, file_name)\n",
    "        df = pd.read_csv(file_path, encoding='latin1')  # 인코딩 변경\n",
    "        channel_data = df.iloc[:, 0].values  # 첫 번째 열의 데이터만 사용\n",
    "        group_data.append(channel_data)\n",
    "    \n",
    "    # 그룹 데이터를 평균하여 새로운 데이터 생성\n",
    "    new_group_data = np.mean(group_data, axis=0)\n",
    "    new_data.append(new_group_data)\n",
    "\n",
    "# 저장할 폴더 경로\n",
    "output_folder_path = '/Users/sh_oh/Library/CloudStorage/Dropbox/Data/2023-1/BDP/ECSMP_Dataset/EEG_train2_csv'\n",
    "\n",
    "# 데이터를 CSV 파일로 저장\n",
    "for i, group_data in enumerate(new_data):\n",
    "    file_name = f\"group_{i+1}.csv\"\n",
    "    file_path = os.path.join(output_folder_path, file_name)\n",
    "    pd.DataFrame(group_data).to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c478d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹 개수 출력\n",
    "print(f\"그룹 개수: {len(grouped_files)}\")\n",
    "\n",
    "# 그룹 이름 출력 (정렬하여)\n",
    "for group_name in sorted(grouped_files.keys()):\n",
    "    print(group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b248902",
   "metadata": {},
   "source": [
    "# EEG preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd40a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 경로 설정\n",
    "eeg_folder_path = '/Users/sh_oh/Library/CloudStorage/Dropbox/Data/2023-1/BDP/ECSMP_Dataset/EEG_train2_csv'\n",
    "\n",
    "# 파일 목록 가져오기\n",
    "file_list = os.listdir(eeg_folder_path)\n",
    "\n",
    "# 전체 데이터를 저장할 리스트\n",
    "data = []\n",
    "\n",
    "# 가장 긴 데이터 길이를 기준으로 zero-padding\n",
    "max_length = 0\n",
    "\n",
    "# 데이터 읽어오기 및 전처리\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(eeg_folder_path, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    channel_data = df.iloc[:, 0].values  # 첫 번째 열의 데이터만 사용\n",
    "    data.append(channel_data)\n",
    "    if len(channel_data) > max_length:\n",
    "        max_length = len(channel_data)\n",
    "\n",
    "# Zero-padding\n",
    "padded_data = pad_sequences(data, maxlen=max_length, padding='post')\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(padded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62964b32",
   "metadata": {},
   "source": [
    "# Denoising AutoEncoder(DAE) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3a47c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "# 가우시안 노이즈 추가\n",
    "def add_gaussian_noise(data, noise_factor):\n",
    "    noise = np.random.normal(loc=0.0, scale=noise_factor, size=data.shape)\n",
    "    noisy_data = data + noise\n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2fa4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising Autoencoder 모델 생성\n",
    "def create_denoising_autoencoder(input_shape, encoding_dim):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    encoded = Flatten()(input_layer)\n",
    "    encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "    # Decoder\n",
    "    decoded = Dense(np.prod(input_shape), activation='sigmoid')(encoded)\n",
    "    decoded = Reshape(input_shape)(decoded)\n",
    "\n",
    "    # Autoencoder\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "accda855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "39/39 [==============================] - 1s 11ms/step - loss: 0.0668\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0423\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0355\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0339\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0307\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0292\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0283\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0276\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0269\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0264\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0264\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0259\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0237\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0230\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0222\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0213\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0208\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0198\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0194\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0184\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0185\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0187\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0225\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0205\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0182\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0169\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0153\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0150\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0147\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0142\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0145\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0154\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0146\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0138\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0135\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0133\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0129\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0125\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0123\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0121\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0119\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0118\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0115\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0114\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0117\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0118\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0118\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0135\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: dense. Existing layers are: ['input_8', 'flatten_6', 'dense_8', 'dense_9', 'reshape_2'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mfit(noisy_data, normalized_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 특징 추출 (인코더의 출력)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m encoder \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mautoencoder\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39m\u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdense\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutput)\n\u001b[1;32m     17\u001b[0m features \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mpredict(normalized_data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3464\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   3462\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name:\n\u001b[1;32m   3463\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[0;32m-> 3464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3465\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Existing layers are: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3466\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(layer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlayer\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3467\u001b[0m     )\n\u001b[1;32m   3468\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3469\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide either a layer name or layer index at `get_layer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3470\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: dense. Existing layers are: ['input_8', 'flatten_6', 'dense_8', 'dense_9', 'reshape_2']."
     ]
    }
   ],
   "source": [
    "# 입력 데이터의 형태\n",
    "input_shape = normalized_data.shape[1:]\n",
    "encoding_dim = 64\n",
    "\n",
    "# 가우시안 노이즈 추가\n",
    "noise_factor = 0.5\n",
    "noisy_data = add_gaussian_noise(normalized_data, noise_factor)\n",
    "\n",
    "# Denoising Autoencoder 모델 생성\n",
    "autoencoder = create_denoising_autoencoder(input_shape, encoding_dim)\n",
    "\n",
    "# 모델 학습\n",
    "autoencoder.fit(noisy_data, normalized_data, epochs=50, batch_size=6, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56135d",
   "metadata": {},
   "source": [
    "# feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e40df7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# 특징 추출 (인코더의 출력)\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('dense_8').output)\n",
    "features = encoder.predict(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7bfbb727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(features.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
